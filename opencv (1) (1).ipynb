{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"JV57DfuMunvR"},"outputs":[],"source":["import cv2"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"Sxtnibcdw_rk","outputId":"3692711e-1aa8-4b75-8d78-56024aa759aa"},"outputs":[{"data":{"text/plain":["'4.5.5'"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["cv2.__version__"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N67x602pxKlT"},"outputs":[],"source":["#import numpy as np\n","#from google.colab.patches import cv2_imshow                   for colab"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"m1oPQbBmx2PW"},"outputs":[],"source":["input = cv2.imread('woman-1979272_1920.jpg')\n","cv2.imshow('Image', input)#for jupyter\n","#cv2_imshow(input)# The first parameter will be title shown on image window,The second parameter is the image varialbe\n","# 'waitKey' allows us to input information when an image window is open\n","# By leaving it blank it just waits for anykey to be pressed before\n","# continuing. By placing numbers (except 0), we can specify a delay for\n","# how long you keep the window open (time is in milliseconds here)\n","cv2.waitKey()\n","# This closes all open windows\n","# Failure to place this will cause your program to hang\n","cv2.destroyAllWindows()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aAG3-43Ry8Yy","outputId":"65991956-0ef3-4cb3-afb2-6a6c9d3bc63d"},"outputs":[{"data":{"text/plain":["(1280, 1920, 3)"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["input.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1FG6ajh70lxo","outputId":"5a41e9bb-1244-4d92-a077-d4856b79b4d2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Height of Image: 1280 pixels\n","Width of Image:  1920 pixels\n"]}],"source":["# Let's print each dimension of the image\n","\n","print('Height of Image:', int(input.shape[0]), 'pixels')\n","print('Width of Image: ', int(input.shape[1]), 'pixels')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5QTG4prI1QPr","outputId":"7f8c4608-ccb4-49ed-eaa6-db14c22850e7"},"outputs":[{"data":{"text/plain":["True"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["# Simply use 'imwrite' specificing the file name and the image to be saved\n","cv2.imwrite('output.jpg', input)\n","cv2.imwrite('output.png', input)"]},{"cell_type":"markdown","metadata":{"id":"pqw8spD21uVL"},"source":["# Face & Eye Detection using HAAR Cascade Classifiers"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":373},"id":"lrIl0QzJ1dNh","outputId":"cab4eb93-17aa-4863-b261-5cbfd1828cbb"},"outputs":[{"name":"stdout","output_type":"stream","text":["[[700  78 134 134]\n"," [183  92 113 113]\n"," [482  84 127 127]\n"," [840 107 126 126]\n"," [356 135 107 107]\n"," [ 23 129 130 130]\n"," [269 250 124 124]\n"," [584 256 124 124]]\n"]}],"source":["import numpy as np\n","import cv2\n","\n","# We point OpenCV's CascadeClassifier function to where our\n","# classifier (XML file format) is stored\n","#face_classifier = cv2.CascadeClassifier(cv2.data.haarcascades +'haarcascade_frontalface_default.xml')\n","face_classifier = cv2.CascadeClassifier(cv2.data.haarcascades +'haarcascade_frontalface_default.xml')\n","# Load our image then convert it to grayscale\n","image = cv2.imread('depositphotos_102766834-stock-photo-group-of-business-people-in.jpg')\n","gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","# Our classifier returns the ROI(range of interest)of the detected face as a tuple\n","# It stores the top left coordinate and the bottom right coordiantes\n","faces = face_classifier.detectMultiScale(gray,scaleFactor= 1.3,minNeighbors= 5)\n","# When no faces detected, face_classifier returns and empty tuple\n","if faces is ():\n","    print(\"No faces found\")\n","# We iterate through our faces array and draw a rectangle\n","# over each face in faces\n","print(faces)\n","for (x,y,w,h) in faces:\n","    cv2.rectangle(image, (x,y), (x+w,y+h), (127,0,255), 2)\n","    cv2.imshow('Face Detection', image)\n","    #cv2_imshow(image)\n","    cv2.waitKey(0)\n","\n","cv2.destroyAllWindows()\n"]},{"cell_type":"markdown","metadata":{"id":"WWtDybQA42B-"},"source":["# Let's combine face and eye detection"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bm563AsAzMjf","outputId":"e2f67514-bd8f-48c9-88d8-a04f8a6b9b86"},"outputs":[{"name":"stdout","output_type":"stream","text":["[[700  78 134 134]\n"," [183  92 113 113]\n"," [482  84 127 127]\n"," [840 107 126 126]\n"," [ 23 129 130 130]\n"," [356 135 107 107]\n"," [269 250 124 124]\n"," [584 256 124 124]]\n"]}],"source":["import numpy as np\n","import cv2\n","\n","face_classifier = cv2.CascadeClassifier(cv2.data.haarcascades +'haarcascade_frontalface_default.xml')\n","eye_classifier = cv2.CascadeClassifier(cv2.data.haarcascades +'haarcascade_eye.xml')\n","\n","img = cv2.imread('depositphotos_102766834-stock-photo-group-of-business-people-in.jpg')\n","gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","\n","faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n","\n","# When no faces detected, face_classifier returns and empty tuple\n","if faces is ():\n","    print(\"No Face Found\")\n","print(faces)\n","for (x,y,w,h) in faces:\n","    cv2.rectangle(img,(x,y),(x+w,y+h),(127,0,255),2)\n","    cv2.imshow('img',img)\n","    cv2.waitKey(0)\n","    roi_gray = gray[y:y+h, x:x+w]  #crop face rectangle\n","    roi_color = img[y:y+h, x:x+w]\n","    eyes = eye_classifier.detectMultiScale(roi_gray)\n","    for (ex,ey,ew,eh) in eyes:\n","        cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(255,255,0),2)\n","        cv2.imshow('img',img)\n","        cv2.waitKey(0)\n","\n","cv2.destroyAllWindows()"]},{"cell_type":"markdown","metadata":{"id":"UPMllezqzMjg"},"source":["# Let's make a live face & eye detection, keeping the face inview at all times"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a18gACN2zMjg"},"outputs":[],"source":["import cv2\n","\n","# Loading the cascades\n","face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades +'haarcascade_frontalface_default.xml')\n","eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades +'haarcascade_eye.xml')\n","\n","# Defining a function that will do the detections\n","def detect(gray, frame):\n","    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n","    for (x, y, w, h) in faces:\n","        cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n","        roi_gray = gray[y:y+h, x:x+w]\n","        roi_color = frame[y:y+h, x:x+w]\n","        eyes = eye_cascade.detectMultiScale(roi_gray, 1.1, 3)\n","        for (ex, ey, ew, eh) in eyes:\n","            cv2.rectangle(roi_color, (ex, ey), (ex+ew, ey+eh), (0, 255, 0), 2)\n","    return frame\n","\n","# Doing some Face Recognition with the webcam\n","video_capture = cv2.VideoCapture(0)\n","while True:\n","    _, frame = video_capture.read()\n","    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n","    canvas = detect(gray, frame)\n","    cv2.imshow('Video', canvas)\n","    if cv2.waitKey(1) & 0xFF == ord('q'):\n","        break\n","video_capture.release()\n","cv2.destroyAllWindows()\n"]},{"cell_type":"markdown","metadata":{"id":"s4RciE1hzMjg"},"source":["# Car & Pedestrian Detection"]},{"cell_type":"raw","metadata":{"id":"9XlY_gIqzMjh"},"source":["#Pedistrian Detection"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RJhnxry1zMjh"},"outputs":[],"source":["import cv2\n","import numpy as np\n","\n","# Create our body classifier\n","body_classifier = cv2.CascadeClassifier(cv2.data.haarcascades +'haarcascade_fullbody.xml')\n","\n","# Initiate video capture for video file\n","cap = cv2.VideoCapture('walking (1).avi')\n","\n","# Loop once video is successfully loaded\n","while cap.isOpened():\n","\n","    # Read first frame\n","    ret, frame = cap.read()\n","    #frame = cv2.resize(frame, None,fx=0.5, fy=0.5, interpolation = cv2.INTER_LINEAR)\n","\n","    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n","    # Pass frame to our body classifier\n","    bodies = body_classifier.detectMultiScale(gray, 1.2, 3)\n","\n","    # Extract bounding boxes for any bodies identified\n","    for (x,y,w,h) in bodies:\n","        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 255), 2)\n","        cv2.imshow('Pedestrians', frame)\n","\n","    if cv2.waitKey(1) == 13: #13 is the Enter Key\n","        break\n","\n","cap.release()\n","cv2.destroyAllWindows()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cCIFsu9AzMjh"},"outputs":[],"source":["# OpenCV Python program to detect cars in video frame\n","# import libraries of python OpenCV\n","import cv2\n","\n","# capture frames from a video\n","cap = cv2.VideoCapture( 'cars.mp4')\n","\n","# Trained XML classifiers describes some features of some object we want to detect\n","car_cascade = cv2.CascadeClassifier( 'cars.xml')\n","\n","# loop runs if capturing has been initialized.\n","while True:\n","    # reads frames from a video\n","    ret, frames = cap.read()\n","    # convert to gray scale of each frames\n","    gray = cv2.cvtColor(frames, cv2.COLOR_BGR2GRAY)\n","    # Detects cars of different sizes in the input image\n","    cars = car_cascade.detectMultiScale( gray, 1.1, 1)\n","    # To draw a rectangle in each cars\n","    for (x,y,w,h) in cars:\n","        cv2.rectangle(frames,(x,y),(x+w,y+h),(0,0,255),2)\n","        # Display frames in a window\n","        cv2.imshow('Car Detection', frames)\n","    # Wait for Enter key to stop\n","    if cv2.waitKey(33) == 8:\n","        break\n","\n","cv2.destroyAllWindows()"]},{"cell_type":"markdown","metadata":{"id":"oM8CAQfhzMjh"},"source":["# Capture and mouse draw rectangle from webcam and sketch process it on a live feed"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xkYCQmhrzMjh"},"outputs":[],"source":["import cv2\n","from matplotlib import pyplot as plt\n","import numpy as np"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5ijrt8SlzMji"},"outputs":[],"source":["def sketch_transform(image):\n","    image_grayscale = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","    image_grayscale_blurred = cv2.GaussianBlur(image_grayscale, (7,7), 0)#for smoothning\n","    image_canny = cv2.Canny(image_grayscale_blurred, 10, 80)#edge detection\n","    _, mask = image_canny_inverted = cv2.threshold(image_canny, 30, 255, cv2.THRESH_BINARY_INV)#assignment of pixel values in relation to the threshold value provided\n","    return mask"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rY4o1bz5zMji"},"outputs":[],"source":["cam_capture = cv2.VideoCapture(0)\n","cv2.destroyAllWindows()\n","\n","while True:\n","    _, im0 = cam_capture.read()\n","    showCrosshair = False\n","    fromCenter = False\n","    r = cv2.selectROI(\"Image\", im0, fromCenter, showCrosshair)\n","    break\n","\n","while True:\n","    _, image_frame = cam_capture.read()\n","\n","    rect_img = image_frame[int(r[1]):int(r[1]+r[3]), int(r[0]):int(r[0]+r[2])]\n","\n","    sketcher_rect = rect_img\n","    sketcher_rect = sketch_transform(sketcher_rect)\n","\n","    #Conversion for 3 channels to put back on original image (streaming)\n","    sketcher_rect_rgb = cv2.cvtColor(sketcher_rect, cv2.COLOR_GRAY2RGB)\n","\n","    #Replacing the sketched image on Region of Interest\n","    image_frame[int(r[1]):int(r[1]+r[3]), int(r[0]):int(r[0]+r[2])] = sketcher_rect_rgb\n","\n","    cv2.imshow(\"Sketcher ROI\", image_frame)\n","\n","    if cv2.waitKey(1) & 0xFF == ord('q'):\n","        break\n","\n","cam_capture.release()\n","cv2.destroyAllWindows()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"trtIm6TxzMji"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.9"}},"nbformat":4,"nbformat_minor":0}